{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "lecture3-notebook-iris.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfirm/iads_day6/blob/main/lecture3_notebook_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKTD-LvVJwcs"
      },
      "source": [
        "# Lecture 3 notebook\n",
        "## Introduction to TensorFlow and Deep Learning\n",
        "\n",
        "## IADS Summer School, 2nd August 2021\n",
        "\n",
        "### Dr Michael Fairbank, University of Essex, UK\n",
        "\n",
        "- Email: m.fairbank@essex.ac.uk\n",
        "- This is a Jupyter Notebook to accompany Lecture 3 of the course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJdE0LUqJwcy"
      },
      "source": [
        "### Load the Iris Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPp0Feh4Jwc0",
        "outputId": "86ace346-986b-4d33-d70f-96ce9197a028"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load CSV files\n",
        "#inputs_train=pd.read_csv('datasets/iris_train.csv',usecols = [0,1,2,3],skiprows = None,header=None).values\n",
        "#labels_train = pd.read_csv('datasets/iris_train.csv',usecols = [4],skiprows = None ,header=None).values.reshape(-1)\n",
        "#inputs_test=pd.read_csv('datasets/iris_test.csv',usecols = [0,1,2,3],skiprows = None,header=None).values\n",
        "#labels_test = pd.read_csv('datasets/iris_test.csv',usecols = [4],skiprows = None ,header=None).values.reshape(-1)\n",
        "# If the above line fails then try instead the following 4 lines, to download it directly from \n",
        "# my google drive account\n",
        "inputs_train=pd.read_csv('https://drive.google.com/uc?export=download&id=15g37AN8yaPJtuQwOnhuNuMIWcMr8vB9C',usecols = [0,1,2,3],skiprows = None,header=None).values\n",
        "labels_train = pd.read_csv('https://drive.google.com/uc?export=download&id=15g37AN8yaPJtuQwOnhuNuMIWcMr8vB9C',usecols = [4],skiprows = None ,header=None).values.reshape(-1)\n",
        "inputs_test=pd.read_csv('https://drive.google.com/uc?export=download&id=1a7ok2PiILjhzrB3cUWmXvBmHY-cpZ6lc',usecols = [0,1,2,3],skiprows = None,header=None).values\n",
        "labels_test = pd.read_csv('https://drive.google.com/uc?export=download&id=1a7ok2PiILjhzrB3cUWmXvBmHY-cpZ6lc',usecols = [4],skiprows = None ,header=None).values.reshape(-1)\n",
        "\n",
        "\n",
        "print(\"Data loaded\")\n",
        "print(\"Train set inputs:\",inputs_train)\n",
        "print(\"Train set labels:\",labels_train)\n",
        "print(\"Test set inputs:\",inputs_test)\n",
        "print(\"Test set labels:\",labels_test)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded\n",
            "Train set inputs: [[6.4 2.8 5.6 2.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [6.  2.2 5.  1.5]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.  3.  4.8 1.8]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.  3.  1.6 0.2]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [5.5 2.4 3.7 1. ]]\n",
            "Train set labels: [2 1 2 0 0 0 0 2 1 0 1 1 0 0 2 1 2 2 2 0 2 2 0 2 2 0 1 2 1 1 1 1 1 2 2 2 2\n",
            " 2 0 0 2 2 2 0 0 2 0 2 0 2 0 1 1 0 1 2 2 2 2 1 1 2 2 2 1 2 0 2 2 0 0 1 0 2\n",
            " 2 0 1 1 1 2 0 1 1 1 2 0 1 1 1 0 2 1 0 0 2 0 0 2 1 0 0 1 0 1 0 0 0 0 1 0 2\n",
            " 1 0 2 0 1 1 0 0 1]\n",
            "Test set inputs: [[5.9 3.  4.2 1.5]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.4 2.9 4.3 1.3]]\n",
            "Test set labels: [1 2 0 1 1 1 0 2 1 2 2 0 2 1 1 0 1 0 0 2 0 1 2 1 1 1 0 1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOcgRTuVJwc2"
      },
      "source": [
        "#### Build the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmwNdWI1Jwc3",
        "outputId": "9caa0c95-65a5-4294-d9b5-743b78ac336a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Neural network\n",
        "hids=[4,20,20,3]\n",
        "layer1=tf.keras.layers.Dense(hids[1], activation='tanh')\n",
        "layer2=tf.keras.layers.Dense(hids[2], activation='tanh')\n",
        "layer3=tf.keras.layers.Dense(hids[3], activation='softmax')\n",
        "model = tf.keras.Sequential([layer1,layer2,layer3])\n",
        "\n",
        "def run_network(x,training=False):\n",
        "    return model(x,training=training)\n",
        "\n",
        "print(run_network(inputs_train[0:1,:])) # we have to run the network once before the trainable_variables are created\n",
        "print(model.summary()) # Prints an overview of a keras model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.186428   0.5112821  0.30228996]], shape=(1, 3), dtype=float32)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (1, 20)                   100       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, 20)                   420       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, 3)                    63        \n",
            "=================================================================\n",
            "Total params: 583\n",
            "Trainable params: 583\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-389B6VJwc3"
      },
      "source": [
        "#### Train the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "549TB-YgJwc4"
      },
      "source": [
        "@tf.function\n",
        "def calc_loss_and_accuracy(inputs, labels, training):\n",
        "    y=run_network(inputs,training)\n",
        "    cce=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    cross_entropy = tf.reduce_mean(cce(y_true=labels, y_pred=y))\n",
        "    total_loss=cross_entropy\n",
        "    correct_predictions = tf.equal(tf.argmax(y, axis=1), labels)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "    k_L2=0.005\n",
        "    lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in trainable_variables ]) \n",
        "    total_loss+=lossL2*k_L2\n",
        "    return [total_loss, accuracy, cross_entropy]\n",
        "\n",
        "@tf.function\n",
        "def calc_training_loss():\n",
        "    return calc_loss_and_accuracy(inputs_train, labels_train, training=True)[0]\n",
        "trainable_variables=model.trainable_variables\n",
        "\n",
        "training_losses=[]\n",
        "test_losses=[]\n",
        "iterations=[]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDemTlR9Jwc6",
        "outputId": "77306eaa-868a-4790-9964-ad2f8194b74d"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "for i in range(10000):\n",
        "    optimizer.minimize(calc_training_loss, trainable_variables)\n",
        "    if (i%100)==0:\n",
        "        [train_loss, train_acc, train_cross_entropy]=calc_loss_and_accuracy(inputs_train, labels_train,training=False)\n",
        "        [test_loss, test_acc, test_cross_entropy]=calc_loss_and_accuracy(inputs_test, labels_test,training=False)\n",
        "        iterations.append(i)\n",
        "        training_losses.append(train_cross_entropy)\n",
        "        test_losses.append(test_cross_entropy)\n",
        "        print(\"iteration \",i,\" loss:\", train_loss.numpy(),\" accuracy:\", train_acc.numpy(), \"testLoss:\",test_loss.numpy(), \"test_accuracy:\", test_acc.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration  0  loss: 0.8636562  accuracy: 1.0 testLoss: 2.0024526 test_accuracy: 0.96666664\n",
            "iteration  100  loss: 0.71980506  accuracy: 1.0 testLoss: 1.7723119 test_accuracy: 0.96666664\n",
            "iteration  200  loss: 0.607956  accuracy: 1.0 testLoss: 1.5505676 test_accuracy: 0.96666664\n",
            "iteration  300  loss: 0.5191511  accuracy: 1.0 testLoss: 1.3289392 test_accuracy: 0.96666664\n",
            "iteration  400  loss: 0.44740823  accuracy: 1.0 testLoss: 1.1222458 test_accuracy: 0.96666664\n",
            "iteration  500  loss: 0.3895251  accuracy: 1.0 testLoss: 0.94517684 test_accuracy: 0.96666664\n",
            "iteration  600  loss: 0.34282908  accuracy: 1.0 testLoss: 0.80092597 test_accuracy: 0.96666664\n",
            "iteration  700  loss: 0.3045248  accuracy: 1.0 testLoss: 0.6795849 test_accuracy: 0.96666664\n",
            "iteration  800  loss: 0.27305317  accuracy: 1.0 testLoss: 0.57830334 test_accuracy: 0.96666664\n",
            "iteration  900  loss: 0.24751651  accuracy: 1.0 testLoss: 0.49642438 test_accuracy: 0.96666664\n",
            "iteration  1000  loss: 0.2269239  accuracy: 1.0 testLoss: 0.4291985 test_accuracy: 0.96666664\n",
            "iteration  1100  loss: 0.21030742  accuracy: 1.0 testLoss: 0.3784554 test_accuracy: 0.96666664\n",
            "iteration  1200  loss: 0.19672766  accuracy: 1.0 testLoss: 0.33804113 test_accuracy: 0.96666664\n",
            "iteration  1300  loss: 0.18552248  accuracy: 1.0 testLoss: 0.30433974 test_accuracy: 0.96666664\n",
            "iteration  1400  loss: 0.17611846  accuracy: 1.0 testLoss: 0.27783418 test_accuracy: 0.96666664\n",
            "iteration  1500  loss: 0.16814709  accuracy: 1.0 testLoss: 0.25606298 test_accuracy: 0.96666664\n",
            "iteration  1600  loss: 0.16135286  accuracy: 1.0 testLoss: 0.23816802 test_accuracy: 0.96666664\n",
            "iteration  1700  loss: 0.15549809  accuracy: 0.9916667 testLoss: 0.22320944 test_accuracy: 0.96666664\n",
            "iteration  1800  loss: 0.15042803  accuracy: 0.9916667 testLoss: 0.21059567 test_accuracy: 0.96666664\n",
            "iteration  1900  loss: 0.14602831  accuracy: 0.9916667 testLoss: 0.19977982 test_accuracy: 0.96666664\n",
            "iteration  2000  loss: 0.14218457  accuracy: 0.98333335 testLoss: 0.19033487 test_accuracy: 0.96666664\n",
            "iteration  2100  loss: 0.1388306  accuracy: 0.98333335 testLoss: 0.18245348 test_accuracy: 0.96666664\n",
            "iteration  2200  loss: 0.13590322  accuracy: 0.98333335 testLoss: 0.17484277 test_accuracy: 0.96666664\n",
            "iteration  2300  loss: 0.13332742  accuracy: 0.98333335 testLoss: 0.16941223 test_accuracy: 0.96666664\n",
            "iteration  2400  loss: 0.13110457  accuracy: 0.98333335 testLoss: 0.16349134 test_accuracy: 0.96666664\n",
            "iteration  2500  loss: 0.12913571  accuracy: 0.98333335 testLoss: 0.15965328 test_accuracy: 0.96666664\n",
            "iteration  2600  loss: 0.12744191  accuracy: 0.9916667 testLoss: 0.15585026 test_accuracy: 0.96666664\n",
            "iteration  2700  loss: 0.12597714  accuracy: 0.9916667 testLoss: 0.15236872 test_accuracy: 0.96666664\n",
            "iteration  2800  loss: 0.12470645  accuracy: 0.9916667 testLoss: 0.14937276 test_accuracy: 0.96666664\n",
            "iteration  2900  loss: 0.12359246  accuracy: 0.9916667 testLoss: 0.14683747 test_accuracy: 0.96666664\n",
            "iteration  3000  loss: 0.12260708  accuracy: 0.9916667 testLoss: 0.14436707 test_accuracy: 0.96666664\n",
            "iteration  3100  loss: 0.12172764  accuracy: 0.9916667 testLoss: 0.14255244 test_accuracy: 0.96666664\n",
            "iteration  3200  loss: 0.12093043  accuracy: 0.9916667 testLoss: 0.14075978 test_accuracy: 0.96666664\n",
            "iteration  3300  loss: 0.12020685  accuracy: 0.9916667 testLoss: 0.13915125 test_accuracy: 0.96666664\n",
            "iteration  3400  loss: 0.119540505  accuracy: 0.9916667 testLoss: 0.13768688 test_accuracy: 0.96666664\n",
            "iteration  3500  loss: 0.118924856  accuracy: 0.9916667 testLoss: 0.13639748 test_accuracy: 0.96666664\n",
            "iteration  3600  loss: 0.11835352  accuracy: 0.9916667 testLoss: 0.13515466 test_accuracy: 0.96666664\n",
            "iteration  3700  loss: 0.11782308  accuracy: 0.9916667 testLoss: 0.13390401 test_accuracy: 0.96666664\n",
            "iteration  3800  loss: 0.1173314  accuracy: 0.9916667 testLoss: 0.13307977 test_accuracy: 0.96666664\n",
            "iteration  3900  loss: 0.116908774  accuracy: 0.9916667 testLoss: 0.13168721 test_accuracy: 0.96666664\n",
            "iteration  4000  loss: 0.116472736  accuracy: 0.9916667 testLoss: 0.13142517 test_accuracy: 0.96666664\n",
            "iteration  4100  loss: 0.11610551  accuracy: 0.9916667 testLoss: 0.13074979 test_accuracy: 0.96666664\n",
            "iteration  4200  loss: 0.115783185  accuracy: 0.9916667 testLoss: 0.13012654 test_accuracy: 0.96666664\n",
            "iteration  4300  loss: 0.115499675  accuracy: 0.9916667 testLoss: 0.12962249 test_accuracy: 0.96666664\n",
            "iteration  4400  loss: 0.11525311  accuracy: 0.9916667 testLoss: 0.12912741 test_accuracy: 0.96666664\n",
            "iteration  4500  loss: 0.11504206  accuracy: 0.9916667 testLoss: 0.1287477 test_accuracy: 0.96666664\n",
            "iteration  4600  loss: 0.11485857  accuracy: 0.9916667 testLoss: 0.12838255 test_accuracy: 0.96666664\n",
            "iteration  4700  loss: 0.11470477  accuracy: 0.9916667 testLoss: 0.128073 test_accuracy: 0.96666664\n",
            "iteration  4800  loss: 0.11457239  accuracy: 0.9916667 testLoss: 0.12778991 test_accuracy: 0.96666664\n",
            "iteration  4900  loss: 0.114461586  accuracy: 0.9916667 testLoss: 0.12737815 test_accuracy: 0.96666664\n",
            "iteration  5000  loss: 0.114360616  accuracy: 0.9916667 testLoss: 0.12732361 test_accuracy: 0.96666664\n",
            "iteration  5100  loss: 0.11427601  accuracy: 0.9916667 testLoss: 0.12712352 test_accuracy: 0.96666664\n",
            "iteration  5200  loss: 0.11420302  accuracy: 0.9916667 testLoss: 0.12693465 test_accuracy: 0.96666664\n",
            "iteration  5300  loss: 0.1141388  accuracy: 0.9916667 testLoss: 0.12678918 test_accuracy: 0.96666664\n",
            "iteration  5400  loss: 0.11408259  accuracy: 0.9916667 testLoss: 0.12668368 test_accuracy: 0.96666664\n",
            "iteration  5500  loss: 0.11403264  accuracy: 0.9916667 testLoss: 0.12651685 test_accuracy: 0.96666664\n",
            "iteration  5600  loss: 0.11399034  accuracy: 0.9916667 testLoss: 0.12628806 test_accuracy: 0.96666664\n",
            "iteration  5700  loss: 0.113950394  accuracy: 0.9916667 testLoss: 0.12629893 test_accuracy: 0.96666664\n",
            "iteration  5800  loss: 0.11391692  accuracy: 0.9916667 testLoss: 0.12621216 test_accuracy: 0.96666664\n",
            "iteration  5900  loss: 0.11389037  accuracy: 0.9916667 testLoss: 0.1262612 test_accuracy: 0.96666664\n",
            "iteration  6000  loss: 0.113863215  accuracy: 0.9916667 testLoss: 0.12606394 test_accuracy: 0.96666664\n",
            "iteration  6100  loss: 0.11384207  accuracy: 0.9916667 testLoss: 0.12605539 test_accuracy: 0.96666664\n",
            "iteration  6200  loss: 0.113823555  accuracy: 0.9916667 testLoss: 0.12594897 test_accuracy: 0.96666664\n",
            "iteration  6300  loss: 0.11380764  accuracy: 0.9916667 testLoss: 0.12591074 test_accuracy: 0.96666664\n",
            "iteration  6400  loss: 0.11379384  accuracy: 0.9916667 testLoss: 0.12588288 test_accuracy: 0.96666664\n",
            "iteration  6500  loss: 0.1137818  accuracy: 0.9916667 testLoss: 0.12583604 test_accuracy: 0.96666664\n",
            "iteration  6600  loss: 0.11377086  accuracy: 0.9916667 testLoss: 0.1258091 test_accuracy: 0.96666664\n",
            "iteration  6700  loss: 0.11376137  accuracy: 0.9916667 testLoss: 0.12582627 test_accuracy: 0.96666664\n",
            "iteration  6800  loss: 0.11375214  accuracy: 0.9916667 testLoss: 0.1257591 test_accuracy: 0.96666664\n",
            "iteration  6900  loss: 0.113765664  accuracy: 0.9916667 testLoss: 0.12612665 test_accuracy: 0.96666664\n",
            "iteration  7000  loss: 0.11373633  accuracy: 0.9916667 testLoss: 0.1257217 test_accuracy: 0.96666664\n",
            "iteration  7100  loss: 0.11372922  accuracy: 0.9916667 testLoss: 0.1257032 test_accuracy: 0.96666664\n",
            "iteration  7200  loss: 0.11372267  accuracy: 0.9916667 testLoss: 0.12568682 test_accuracy: 0.96666664\n",
            "iteration  7300  loss: 0.11371651  accuracy: 0.9916667 testLoss: 0.12567577 test_accuracy: 0.96666664\n",
            "iteration  7400  loss: 0.11371149  accuracy: 0.9916667 testLoss: 0.12573522 test_accuracy: 0.96666664\n",
            "iteration  7500  loss: 0.11370531  accuracy: 0.9916667 testLoss: 0.1256522 test_accuracy: 0.96666664\n",
            "iteration  7600  loss: 0.11376727  accuracy: 0.9916667 testLoss: 0.12635143 test_accuracy: 0.96666664\n",
            "iteration  7700  loss: 0.11369537  accuracy: 0.9916667 testLoss: 0.1256362 test_accuracy: 0.96666664\n",
            "iteration  7800  loss: 0.11369075  accuracy: 0.9916667 testLoss: 0.12562527 test_accuracy: 0.96666664\n",
            "iteration  7900  loss: 0.11368653  accuracy: 0.9916667 testLoss: 0.12563625 test_accuracy: 0.96666664\n",
            "iteration  8000  loss: 0.113682434  accuracy: 0.9916667 testLoss: 0.12561217 test_accuracy: 0.96666664\n",
            "iteration  8100  loss: 0.11368041  accuracy: 0.9916667 testLoss: 0.12550132 test_accuracy: 0.96666664\n",
            "iteration  8200  loss: 0.11367507  accuracy: 0.9916667 testLoss: 0.12559956 test_accuracy: 0.96666664\n",
            "iteration  8300  loss: 0.113671646  accuracy: 0.9916667 testLoss: 0.12559941 test_accuracy: 0.96666664\n",
            "iteration  8400  loss: 0.1136685  accuracy: 0.9916667 testLoss: 0.12559593 test_accuracy: 0.96666664\n",
            "iteration  8500  loss: 0.11366549  accuracy: 0.9916667 testLoss: 0.12558803 test_accuracy: 0.96666664\n",
            "iteration  8600  loss: 0.11366528  accuracy: 0.9916667 testLoss: 0.12571487 test_accuracy: 0.96666664\n",
            "iteration  8700  loss: 0.11366007  accuracy: 0.9916667 testLoss: 0.12558037 test_accuracy: 0.96666664\n",
            "iteration  8800  loss: 0.11365795  accuracy: 0.9916667 testLoss: 0.12562957 test_accuracy: 0.96666664\n",
            "iteration  8900  loss: 0.11365531  accuracy: 0.9916667 testLoss: 0.125568 test_accuracy: 0.96666664\n",
            "iteration  9000  loss: 0.11365314  accuracy: 0.9916667 testLoss: 0.12557338 test_accuracy: 0.96666664\n",
            "iteration  9100  loss: 0.11365913  accuracy: 0.9916667 testLoss: 0.12580045 test_accuracy: 0.96666664\n",
            "iteration  9200  loss: 0.11364932  accuracy: 0.9916667 testLoss: 0.12556994 test_accuracy: 0.96666664\n",
            "iteration  9300  loss: 0.11364759  accuracy: 0.9916667 testLoss: 0.12556778 test_accuracy: 0.96666664\n",
            "iteration  9400  loss: 0.113646924  accuracy: 0.9916667 testLoss: 0.12549078 test_accuracy: 0.96666664\n",
            "iteration  9500  loss: 0.11364454  accuracy: 0.9916667 testLoss: 0.12556466 test_accuracy: 0.96666664\n",
            "iteration  9600  loss: 0.113643244  accuracy: 0.9916667 testLoss: 0.12554054 test_accuracy: 0.96666664\n",
            "iteration  9700  loss: 0.11364195  accuracy: 0.9916667 testLoss: 0.12555659 test_accuracy: 0.96666664\n",
            "iteration  9800  loss: 0.11364079  accuracy: 0.9916667 testLoss: 0.12556177 test_accuracy: 0.96666664\n",
            "iteration  9900  loss: 0.11364113  accuracy: 0.9916667 testLoss: 0.12546904 test_accuracy: 0.96666664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "H6jbv7dgJwc7",
        "outputId": "205d2d9d-8a0f-4063-a400-8627d4c887fc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(iterations,training_losses,label=\"train\")\n",
        "plt.plot(iterations,test_losses,label=\"test\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel('Cross-Entropy Loss')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COa3-XcNJwc9"
      },
      "source": [
        "## End of lecture 3\n"
      ]
    }
  ]
}