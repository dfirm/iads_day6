{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOuoVS0KdDZoIg4BMjxJecm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfirm/iads_day6/blob/main/XOR_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M3SbTvjS4X4",
        "outputId": "c3abb319-ee8b-4b07-d101-96424f60ad11"
      },
      "source": [
        "import os,sys\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant([[0,0],[0,1],[1,0],[1,1]], tf.float32) # our input vector\n",
        "\n",
        "# Build our random weight and bias matrices, of appropriate shapes\n",
        "\n",
        "W1 = tf.Variable(tf.random.truncated_normal([2, 2], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([1, 2], stddev=0.1, seed=2))\n",
        "W2 = tf.Variable(tf.random.truncated_normal([2, 1], stddev=0.1, seed=3))\n",
        "b2 = tf.Variable(tf.random.truncated_normal([1, 1], stddev=0.1, seed=4))\n",
        "\n",
        "y_labels = tf.constant([[0], [1], [1], [0]], tf.float32)  # TODO\n",
        "\n",
        "def run_network(x):\n",
        "    h1 = tf.sigmoid(tf.matmul( x, W1) + b1)  # TODO\n",
        "    y=   tf.sigmoid(tf.matmul(h1, W2) + b2)  # TODO\n",
        "    return y\n",
        "\n",
        "def calc_loss():\n",
        "    y = run_network(x)\n",
        "    deltas = tf.subtract(y, y_labels)\n",
        "    squared_deltas = tf.square(deltas)\n",
        "    loss = tf.reduce_sum(squared_deltas)\n",
        "    return loss\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(0.5)\n",
        "\n",
        "for i in range(20000):\n",
        "    optimizer.minimize(calc_loss, [W1, b1, W2, b2])\n",
        "    if (i%1000)==0:\n",
        "        print(\"iteration \",i,\" loss\", calc_loss().numpy())\n",
        "        \n",
        "print(run_network(x).numpy())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration  0  loss 1.000001\n",
            "iteration  1000  loss 0.9999995\n",
            "iteration  2000  loss 0.99999857\n",
            "iteration  3000  loss 0.99999636\n",
            "iteration  4000  loss 0.99998933\n",
            "iteration  5000  loss 0.99993926\n",
            "iteration  6000  loss 0.78546774\n",
            "iteration  7000  loss 0.007361976\n",
            "iteration  8000  loss 0.003089208\n",
            "iteration  9000  loss 0.0019297409\n",
            "iteration  10000  loss 0.0013965681\n",
            "iteration  11000  loss 0.0010916909\n",
            "iteration  12000  loss 0.00089484884\n",
            "iteration  13000  loss 0.00075748307\n",
            "iteration  14000  loss 0.0006562775\n",
            "iteration  15000  loss 0.0005786761\n",
            "iteration  16000  loss 0.0005173129\n",
            "iteration  17000  loss 0.00046759742\n",
            "iteration  18000  loss 0.00042650703\n",
            "iteration  19000  loss 0.00039199286\n",
            "[[0.00950232]\n",
            " [0.9910499 ]\n",
            " [0.9890821 ]\n",
            " [0.0085454 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}