{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "lecture4-notebook-cnn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfirm/iads_day6/blob/main/lecture4_notebook_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmI1KVIkHid"
      },
      "source": [
        "# Lecture 4 notebook (Convolutional Neural Networks)\n",
        "## Introduction to TensorFlow and Deep Learning\n",
        "\n",
        "## IADS Summer School, 2nd August 2021\n",
        "\n",
        "### Dr Michael Fairbank, University of Essex, UK\n",
        "\n",
        "- Email: m.fairbank@essex.ac.uk\n",
        "- This is a Jupyter Notebook to accompany Lecture 4 of the course\n",
        "\n",
        "## Training a CNN vision Classifier\n",
        "\n",
        "- Objectives: Learn more about CNN networks\n",
        "- Co-objective: Learn about standard Keras vision benchmarks datasets - MNIST, CIFAR-10, Mnist-Fashion\n",
        "\n",
        "### Instructions: \n",
        "\n",
        "1. Go through each code block, study and make sure you understand each of them, and fill in the missing \"TODO\" parts.\n",
        "\n",
        "2. Work though the \"checklist of things to do\" in the final block of this page.\n",
        "\n",
        "Before you start\n",
        "- Check you have the python packages numpy, matplotlib, tensorflow.\n",
        "- e.g. install them with \"pip3 install numpy, matplotlib, tensorflow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjP6SNd9kHii"
      },
      "source": [
        "## Load a vision benchmark dataset\n",
        "\n",
        "- We will start with the MNIST hand-written numeric digits dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnHdBL0FkHij"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "dataset_name=\"cifar10\"\n",
        "if dataset_name==\"cifar10\":\n",
        "    dataset = tf.keras.datasets.cifar10\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    # CIFAR10 images are 32*32*3. \n",
        "elif dataset_name==\"fashion\":\n",
        "    dataset = tf.keras.datasets.fashion_mnist\n",
        "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "elif dataset_name==\"mnist\":\n",
        "    dataset = tf.keras.datasets.mnist\n",
        "    class_names = ['zero', 'one', 'two', 'three', 'four','five', 'six', 'seven', 'eight', 'nine']\n",
        "else:\n",
        "    print(\"unknown dataset\")\n",
        "    sys.exit(0)\n",
        "(train_images0, train_labels0),(test_images0, test_labels0) = dataset.load_data()\n",
        "print('Train: X=%s, y=%s' % (train_images0.shape, train_labels0.shape))\n",
        "print('Test: X=%s, y=%s' % (test_images0.shape, test_labels0.shape))\n",
        "train_labels=train_labels0.reshape(-1)\n",
        "test_labels=test_labels0.reshape(-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbf3nJ6pkHil"
      },
      "source": [
        "## Visualise the Dataset\n",
        "\n",
        "- Show pictures of the images we are trying to learn..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ0mFPEVkHil"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot first few images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    # define subplot\n",
        "    plt.subplot(5,5,i+1)\n",
        "    # plot raw pixel data\n",
        "    plt.imshow(train_images0[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    if class_names!=None:\n",
        "        # Add a label underneath, if we have one...\n",
        "        plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbG5TtKPkHim"
      },
      "source": [
        "## Prep the data\n",
        "- The keras datasets contain integer pixel intensities from 0 to 255.  We must rescale this to floats from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEJrbJhtkHin"
      },
      "source": [
        "# Rescale greyscale from 8 bit to floating point (by dividing by 255)\n",
        "test_images=(test_images0/255.0).astype(np.float32) # 10000 test patterns, shape 10000*28*28  \n",
        "train_images=(train_images0/255.0).astype(np.float32) # 60000 train patterns, shape 60000*28*28\n",
        "\n",
        "if len(train_images.shape)==3:\n",
        "    # add a single channel to these black-and-white images\n",
        "    train_images=train_images.reshape(list(train_images.shape)+[1])\n",
        "    test_images=test_images.reshape(list(test_images.shape)+[1])\n",
        "    print(\"Reshaped images from \",train_images0.shape,\"to\",train_images.shape,\"so that 'channel' dimension exists\")\n",
        "\n",
        "num_classification_categories=train_labels.max()+1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLdfpJdmkHio"
      },
      "source": [
        "## Define a model\n",
        "- Build our neural network here.\n",
        "- Use relu activation functions everywhere, **except for the last layer which must have no activation function** (because the softmax is added in the training loop with the \"SparseCategoricalCrossentropy(from_logits=True)\" line below).\n",
        "- use kernel size (3,3) for each convolutional layer, and pool size (2,2) for each max-pooling layer.  You can use any kind of padding or other options that you feel is reasonable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9Ym-oNkHip"
      },
      "source": [
        "# build FFNN with CNN architecture.  Add more layers here as you see fit to try to improve the final result.\n",
        "keras_model = keras.Sequential()\n",
        "keras_model.add(layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
        "keras_model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "keras_model.add(layers.Flatten())\n",
        "keras_model.add(layers.Dense(128, activation='relu'))\n",
        "keras_model.add(layers.Dense(num_classification_categories, activation=None))# Deliberately putting no activation function on the final layer because I use \"fromLogits=True\" below.  This trick aids numerical stability for autodiff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koXjTVr_kHir"
      },
      "source": [
        "## View Model Summary\n",
        "\n",
        "- have a look at the model summary here.\n",
        "\n",
        "- Try to verify that the number of parameters of each layer matches what you calculate it should be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko7bjgrAkHis"
      },
      "source": [
        "keras_model.build(input_shape=(None,)+train_images.shape[1:])\n",
        "keras_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlSGZA7kkHis"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHIfh5TjkHit"
      },
      "source": [
        "optimizer=keras.optimizers.Adam()\n",
        "\n",
        "keras_model.compile(optimizer=optimizer,  \n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # From_logits=True tells the SparseCategoricalCrossEntropy function to apply its own softmax (because it wasn't done before).  This trick aids numerical stability.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = keras_model.fit(train_images, train_labels,\n",
        "                batch_size=128,\n",
        "                epochs=5,\n",
        "                validation_data=(test_images, test_labels))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0uTKtRCkHit"
      },
      "source": [
        "## Plot graphs of learning progress...\n",
        "\n",
        "- Have a look at these graphs, and try to work out whether any overfitting has occurred, or whether we would gain any benefit for training for more or fewer epochs (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syqAWLA1kHiu"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLpwFLLkHiu"
      },
      "source": [
        "## Inspect how well the system is working...\n",
        "- The test set has a lot of images in it, but we can only view 25 at a time.\n",
        "- Hence rerun this code block several times, to get a different random set of samples from the test set (TODO)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKzH2OoWkHiu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "# plot 25 random images from the test set.\n",
        "first_index=np.random.randint(len(test_images)-25)\n",
        "for i in range(first_index,first_index+25):\n",
        "    # define subplot\n",
        "    plt.subplot(5,5,i+1-first_index)\n",
        "    # plot raw pixel data\n",
        "    plt.imshow(test_images0[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    if class_names!=None:\n",
        "        # Add a label underneath, if we have one...\n",
        "        prediction=keras_model(test_images[i:i+1])[0,:]\n",
        "        prediction_class=np.argmax(prediction)\n",
        "        true_label=test_labels[i]\n",
        "        class_name=class_names[prediction_class]\n",
        "        plt.xlabel(class_name+\" \"+(\"CORRECT\" if prediction_class==true_label else \"WRONG\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7QVigKvkHiu"
      },
      "source": [
        "## Checklist of things to do\n",
        "\n",
        "1. Check you have made 3 different vision classifiers; for Mnist, mnist-fashion and for cifar10.  No need to bother with cifar100. (TODO)\n",
        "\n",
        "2. Check in each case you have inspected the results, the validation accuracy and decided whether more or fewer epochs would be required. (TODO)\n",
        "\n",
        "3. If you have time remaining then see if you can improve performance on Cifar10.  Possible methods:  Try training for longer.  Add more convolutional layers.  Add more filters at each convolutional layer.    If you view the CNN structure used here: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/ (read the final architecture he used at the bottom of the page) then you can see how to score >80% on CIFAR10.  But it requires a lot of CPU/GPU time to get there.  See the next note on google colab for free GPU usage.\n",
        "\n",
        "4. Try running your notebook in **google colab**, for free extra GPU speed.  \n",
        "\n",
        "5. If time permits, then see what the effect of changing the relu activation functions to tanh.\n",
        "\n",
        "6. If time permits, then try removing all of the convolutional layers, and just have a fully-connected classifier.  Remember you still need the flatten layers though as these images are each rank3 tensors.\n"
      ]
    }
  ]
}